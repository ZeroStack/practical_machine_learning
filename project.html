<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Practical Machine Learning Course: Project</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Practical Machine Learning Course: Project</h1>

<h3>Introduction</h3>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. </p>

<p>This document will attempt to demonstrate the use of data from accelerometers to predict the manner in which the exercise was conducted.</p>

<h3>Data</h3>

<p>The training data for this project are available here:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>

<p>The test data are available here:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>

<p>The data for this project come from this source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.</p>

<h3>Load Relevant Libraries</h3>

<pre><code class="r">library(caret)
</code></pre>

<h3>Download and Read Data</h3>

<p>This section will download and read the data into R.</p>

<pre><code class="r"># Download Data
trainUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
testUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;

trainFile &lt;- &quot;./data/pml-training.csv&quot;
testFile  &lt;- &quot;./data/pml-testing.csv&quot;

if (!file.exists(&quot;./data&quot;)) {
  dir.create(&quot;./data&quot;)
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method=&quot;curl&quot;)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method=&quot;curl&quot;)
}

# Read data
trainRaw &lt;- read.csv(&quot;./data/pml-training.csv&quot;)
testRaw &lt;- read.csv(&quot;./data/pml-testing.csv&quot;)
</code></pre>

<h3>Clean Data</h3>

<p>In this step, we will clean the data. This will involve ridding missing values and meaningless variables that will deliver poorer results.</p>

<p>Check dimensions prior to any adjustments.</p>

<pre><code class="r"># Check dimensions 
dim(trainRaw)
</code></pre>

<pre><code>## [1] 19622   160
</code></pre>

<pre><code class="r">dim(testRaw)
</code></pre>

<pre><code>## [1]  20 160
</code></pre>

<p>Check for NA values</p>

<pre><code class="r">sum(complete.cases(trainRaw))
</code></pre>

<pre><code>## [1] 406
</code></pre>

<pre><code class="r">sum(complete.cases(testRaw))
</code></pre>

<pre><code>## [1] 0
</code></pre>

<p>Remove missing values</p>

<pre><code class="r">trainRaw &lt;- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw &lt;- testRaw[, colSums(is.na(testRaw)) == 0] 
</code></pre>

<p>Remove columns that are not significant contributors.</p>

<pre><code class="r">classe &lt;- trainRaw$classe
trainRemove &lt;- grepl(&quot;^X|timestamp|window&quot;, names(trainRaw))
trainRaw &lt;- trainRaw[, !trainRemove]
trainCleaned &lt;- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe &lt;- classe
testRemove &lt;- grepl(&quot;^X|timestamp|window&quot;, names(testRaw))
testRaw &lt;- testRaw[, !testRemove]
testCleaned &lt;- testRaw[, sapply(testRaw, is.numeric)]
</code></pre>

<p>Compare dimensions of trainRaw and trainCleaned</p>

<pre><code class="r">dim(trainRaw) ; dim(trainCleaned)
</code></pre>

<pre><code>## [1] 19622    87
</code></pre>

<pre><code>## [1] 19622    53
</code></pre>

<h3>Create Data Partitions</h3>

<p>Here, we will create data partitions. The training set will be formed of 70% of the trainRaw data after cleansing.</p>

<pre><code class="r">set.seed(12345) # Reproducibile segment
inTrain &lt;- createDataPartition(trainCleaned$classe, p = 0.70, list = FALSE)

trainData &lt;- trainCleaned[inTrain, ]
testData &lt;- trainCleaned[-inTrain, ]
</code></pre>

<h3>Data Modeling</h3>

<p>I chose to fit a predictive model with the Random Forest algorithm. Random Forests grow many classification trees to classify a new object. This works on individual trees acting on a &#39;voting&#39; system for that class.</p>

<p>The model is accurate at a trade-off for speed, which is not an immediate need.</p>

<p>For the Random Forest, I used a 5-fold cross validation.</p>

<pre><code class="r">controlRf &lt;- trainControl(method=&quot;cv&quot;, 5)
modelRf &lt;- train(classe ~ ., data=trainData, method=&quot;rf&quot;, trControl=controlRf, ntree=250)
modelRf
</code></pre>

<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## 
## Summary of sample sizes: 10989, 10990, 10990, 10989, 10990 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9913372  0.9890408  0.001042652  0.001319170
##   27    0.9903181  0.9877518  0.000983576  0.001244985
##   52    0.9857320  0.9819505  0.001190140  0.001505432
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.
</code></pre>

<h3>Apply Prediction Model to Partion Test Data Set</h3>

<p>Apply prediction model to the test data set created at the data partition step.</p>

<pre><code class="r">predictRf &lt;- predict(modelRf, testData)
cM &lt;- confusionMatrix(testData$classe, predictRf)
cM
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    1    0    0    0
##          B   13 1121    5    0    0
##          C    0   16 1007    3    0
##          D    0    0   24  940    0
##          E    0    0    0    3 1079
## 
## Overall Statistics
##                                           
##                Accuracy : 0.989           
##                  95% CI : (0.9859, 0.9915)
##     No Information Rate : 0.2865          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.986           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9923   0.9851   0.9720   0.9937   1.0000
## Specificity            0.9998   0.9962   0.9961   0.9951   0.9994
## Pos Pred Value         0.9994   0.9842   0.9815   0.9751   0.9972
## Neg Pred Value         0.9969   0.9964   0.9940   0.9988   1.0000
## Prevalence             0.2865   0.1934   0.1760   0.1607   0.1833
## Detection Rate         0.2843   0.1905   0.1711   0.1597   0.1833
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9960   0.9906   0.9840   0.9944   0.9997
</code></pre>

<p>Determine accuracy and out-of-sample error. </p>

<pre><code class="r">accuracy &lt;- postResample(predictRf, testData$classe)
accuracy
</code></pre>

<pre><code>##  Accuracy     Kappa 
## 0.9889550 0.9860251
</code></pre>

<p>The out-of-sample error is accuracy subtracted from 1.</p>

<pre><code class="r">outSE &lt;- 1 - as.numeric(cM$overall[1])
outSE
</code></pre>

<pre><code>## [1] 0.01104503
</code></pre>

<p>Our final values are:
Accuracy: 0.9940527 or 99.40%
Out-of-Sample Error: 0.0059473 or 0.60%</p>

<p>This is classed as a good predicton algorithm as it is abve the 80% accuracy threshold.</p>

<h3>Apply Prediction Model to Test Data Set</h3>

<p>This is the final portion of the assignment; where we will apply the prediction algorithm to the 20 row test set downloaded in the beginning of the project.</p>

<pre><code class="r">result &lt;- predict(modelRf, testCleaned)
result
</code></pre>

<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>

<h3>Function to create submission files</h3>

<pre><code class="r"># Write files for submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0(&quot;./data/submission/problem_id_&quot;,i,&quot;.txt&quot;)
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
</code></pre>

</body>

</html>
